TORCH_COMPILE:
  dynamic: False


GENERAL:
  name: IIIT_WVU
  seed: 47
  rgb: False
  resolution: &resolution [ 256, 256 ]
  accumulation_steps: 2
  max_epochs: 600
  milestones: 30
  truncate: 30
  warmup: 60
  data_root: /home/leo/data
  data:
    pretrain:
      - LivDet2017
    train:
      SelfTraining:
        config:
          skip: False
          selftraining: True
        paths:
          # - LivDet2017/Clarkson/train
          - LivDet2017/Clarkson/test
          - LivDet2017/IIIT_WVU/train
          - LivDet2017/IIIT_WVU/test
          - LivDet2017/NotreDame/train
          - LivDet2017/NotreDame/test
      IIIT_WVU:
        config:
          skip: False
          selftraining: False
        paths:
          - LivDet2017/IIIT_WVU/train
    test:
      Clarkson:
        config:
          gan: True
        paths:
          - LivDet2017/Clarkson/test
      IIIT_WVU:
        config:
          gan: True
        paths:
          - LivDet2017/IIIT_WVU/test
      NotreDame:
        config:
          gan: True
        paths:
          - LivDet2017/NotreDame/test

CLASSIFIER:
  confidence_selfTraining: 0.9
  confidence_CUT: 0.8
  refresh_selftraining: 10
  batch_size: 64
  pad_token_id: -1
  self_training: False
  pretrain:
    batch_size: 8
    apply: False
    epochs: 5
    temperature: 0.07
    config:
      num_crops: [ 2, 4 ]
      crop_sizes: [ 224, 96 ]
      min_scale: [ 0.15, 0.05 ]
      max_scale: [ 1.0,  0.2 ]
      distortion_strength: 1.0
      sigma_range: [ 0.1, 2.0 ]
      gaussian_std: [ 0.1, 0.05 ]
    optimizer:
      type: torch.optim.Adam
      params:
        lr: 1.0e-3
    scheduler:
      type: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
      params:
        T_0: 250
        T_mult: 2
  model:
    type: torchvision.models.resnet50
    params:
      weights: DEFAULT
    replacements:
      - name: "conv1"
        type: torch.nn.Conv2d
        params:
          in_channels: 1
          out_channels: 64
          kernel_size: 7
          stride: 2
          padding: 3
          bias: False
      - name: "fc"
        type: torch.nn.Linear
        params:
          in_features: 2048
          out_features: 2
          bias: True
    extractor:
      features:
        - features.7
  optimizer:
    type: monai.optimizers.Novograd
    params:
      lr: 1.0e-3
      weight_decay: 1.0e-4
      eps: 1.0e-6
    group:
      -
        params: features
        lr: 1.0e-3
        weight_decay: 1.0e-3
        eps: 1.0e-6
      -
        params: classifier
        lr: 3.0e-4
        eps: 1.0e-6
  scheduler:
    type: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
    params:
      T_0: 30
      T_mult: 2
  net_init:
    init_type: normal
    init_gain: 0.02

CUT:
  batch_size: 4
  apply: True
  iterative: True
  update_freq: 5
  flip_equivariance: False
  lambda_GAN: 1.0
  lambda_NCE: 0.25
  nce_layers: [ 0,4,8,12,16,20 ]
  nce_T: 0.07
  nce_idt: True
  mode: lsgan
  netG:
    params:
      ngf: 64
      norm: batch
      use_dropout: True
      n_blocks: 12
      padding_type: reflect
      no_antialias: False
      no_antialias_up: False
    optimizer:
      type: torch.optim.Adam
      params:
        lr: 5.0e-5
        betas: [ 0.75, 0.999 ]
        weight_decay: 1.0e-3
        eps: 1.0e-6
    scheduler:
      type: torch.optim.lr_scheduler.ReduceLROnPlateau
      params:
        mode: "min"
        factor: 0.5
        patience: 5
        cooldown: 2
        min_lr: 1.0e-7
    net_init:
      init_type: normal
      init_gain: 0.02
  netD:
    params:
      ndf: 64
      n_layers: 6
      no_antialias: False
      norm: batch
    optimizer:
      type: torch.optim.Adam
      params:
        lr: 5.0e-5
        betas: [ 0.75, 0.999 ]
        weight_decay: 1.0e-3
        eps: 1.0e-6
    scheduler:
      type: torch.optim.lr_scheduler.ReduceLROnPlateau
      params:
        mode: "min"
        factor: 0.5
        patience: 5
        cooldown: 2
        min_lr: 1.0e-7
    net_init:
      init_type: normal
      init_gain: 0.02
  netF:
    params:
      use_mlp: True
      nc: 256
      num_patches: 128
    optimizer:
      type: monai.optimizers.Novograd
      params:
        lr: 5.0e-5
        betas: [ 0.999, 0.999 ]
        weight_decay: 1.0e-3
        eps: 1.0e-6
    scheduler:
      type: torch.optim.lr_scheduler.ReduceLROnPlateau
      params:
        mode: "min"
        factor: 0.5
        patience: 5
        cooldown: 2
        min_lr: 1.0e-7
    net_init:
      init_type: normal
      init_gain: 0.02

AUGMENTATION:
  RandomHorizontalFlip:
    origin: torchvision.transforms
    params:
      p: 0.5
  RandomVerticalFlip:
    origin: torchvision.transforms
    params:
      p: 0.5
  RandomResizedCrop:
    origin: torchvision.transforms
    params:
      size: *resolution
      scale: !!python/tuple [ 0.6, 0.95 ]
  GaussianBlur:
    origin: torchvision.transforms
    params:
      kernel_size: 7
      sigma: [0.1, 3.0]
