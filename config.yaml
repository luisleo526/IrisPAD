GENERAL:
  name: apple2orange
  rgb: False
  resolution: &resolution [ 128, 128 ]
  max_epochs: 1000
  pad_token_id: -1
  data:
    train:
      IIIT_WVU:
        config:
          skip: False
        paths:
          - /data/dataset/LivDet2017/IIIT_WVU/train
#      Clarkson:
#        config:
#          skip: True
#        paths:
#          - /data/dataset/LivDet2017/Clarkson/train
#      NotreDame:
#        config:
#          skip: True
#        paths:
#          - /data/dataset/LivDet2017/NotreDame/train
    test:
      Clarkson:
        config:
          gan: True
        paths:
          - /data/dataset/LivDet2017/Clarkson/test
      IIIT_WVU:
        config:
          gan: True
        paths:
          - /data/dataset/LivDet2017/IIIT_WVU/test
      NotreDame:
        config:
          gan: True
        paths:
          - /data/dataset/LivDet2017/NotreDame/test
  net_init:
    init_type: normal
    init_gain: 0.02

CLASSIFIER:
  batch_size: 64
  warmup: 20
  model:
    type: torchvision.models.efficientnet_b0
    params:
      weights: DEFAULT
    replacements:
      -
        name: "features.0.0"
        type: torch.nn.Conv2d
        params:
          in_channels: 1
          out_channels: 32
          kernel_size: 3
          stride: 2
          padding: 1
          bias: False
      -
        name: "classifier.1"
        type: torch.nn.Linear
        params:
          in_features: 1280
          out_features: 2
          bias: True
  optimizer:
    type: monai.optimizers.Novograd
    params:
      amsgrad: True
      lr: 1.0e-3
      weight_decay: 1.0e-3
  scheduler:
    type: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
    params:
      T_0: 2000
      T_mult: 2
      eta_min: 1.0e-5

CUT:
  batch_size: 32
  apply: True
  iterative: True
  update_freq: 5
  warmup: 20
  flip_equivariance: False
  lambda_GAN: 1.0
  lambda_NCE: 1.0
  nce_layers: [ 0,4,8,12,16 ]
  nce_T: 0.07
  nce_idt: True
  mode: lsgan
  netG:
    params:
      ngf: 64
      norm: batch
      use_dropout: False
      n_blocks: 9
      padding_type: reflect
      no_antialias: False
      no_antialias_up: False
    optimizer:
      type: torch.optim.Adam
      params:
        lr: 5.0e-4
        betas: [ 0.5, 0.999 ]
        weight_decay: 1.0e-3
    scheduler:
      type: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
      params:
        T_0: 2500
        T_mult: 2
        eta_min: 5.0e-4
  netD:
    params:
      ndf: 64
      n_layers: 3
      no_antialias: False
      norm: batch
    optimizer:
      type: torch.optim.Adam
      params:
        lr: 5.0e-4
        betas: [ 0.75, 0.999 ]
        weight_decay: 1.0e-3
    scheduler:
      type: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
      params:
        T_0: 2500
        T_mult: 2
        eta_min: 5.0e-4
  netF:
    params:
      use_mlp: True
      nc: 256
      num_patches: 64
    optimizer:
      type: torch.optim.Adam
      params:
        lr: 2.0e-4
        betas: [ 0.75, 0.999 ]
        weight_decay: 1.0e-3
    scheduler:
      type: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
      params:
        T_0: 2500
        T_mult: 2
        eta_min: 2.0e-4

AUGMENTATION:
  RandomHorizontalFlip:
    origin: torchvision.transforms
    params:
      p: 0.5
  RandomVerticalFlip:
    origin: torchvision.transforms
    params:
      p: 0.5
  RandomResizedCrop:
    origin: torchvision.transforms
    params:
      size: *resolution
      scale: !!python/tuple [ 0.6, 0.95 ]



